---
layout: post
title: Chest Xray results
published: true
draft: true
---


## Training on 20k images

![](https://i.imgur.com/GwHH4qK.jpg)


## Training on 360k images (Entire MIMIC dataset)

![](https://i.imgur.com/5pIiuDw.jpg)



## Inversion of images not seen during training (old model)


Real
![](https://i.imgur.com/NDnvPjE.png)

Inverted
![](https://i.imgur.com/6cwRGT6.jpg)


<!-- ## Inversion of out-of-distribution images

Real
![](https://i.imgur.com/Ylj2ca8.jpg)

Inverted
![](https://i.imgur.com/SvOdZHq.jpg)
 -->

## Brains - works really well (qualitatively)

- Trained on 8,000 brain slices from 5 datasets
- Problem is easier though because brains are already registered rigidly, so it removes a lot of variation due to pose, ...)
- Also resolution is smaller, 256x256

Real
![](https://i.imgur.com/samY1tk.jpg)

Fake
![](https://i.imgur.com/JvsDI4X.jpg)


## Microscopy images - also works quite well (qualitatively)

- PANDAS 2020 dataset with prostate cancer (11k images, augmented through rotations to 70k)
- 512x512 model resolution, original files have larger resolutions, but variable across images (e.g. 1500x1700, 1650x1900, 400x1800, etc ...).

Fake
![](https://i.imgur.com/4GxUSWE.jpg)

Real
![](https://i.imgur.com/OlyuTVC.jpg)


Fake
![](https://i.imgur.com/DDQ740K.png)

Real
![](https://i.imgur.com/tzfv0KE.png)
